{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process_text_data(bounding_boxes, recognized_strings, rt, rr):\n",
    "    # Step 1: Calculate average height of bounding boxes\n",
    "    heights = [box[3] - box[1] for box in bounding_boxes]  # Assuming box format is [xmin, ymin, xmax, ymax]\n",
    "    rh = np.mean(heights)\n",
    "\n",
    "    # Step 2: Normalize y coordinates\n",
    "    for box in bounding_boxes:\n",
    "        box[1] /= rh\n",
    "        box[3] /= rh\n",
    "\n",
    "    # Step 3: Sort bounding boxes by y and then x\n",
    "    bounding_boxes.sort(key=lambda x: (x[1], x[0]))\n",
    "\n",
    "    # Step 4: Get unique y values of center points\n",
    "    y_centers = [(box[1] + box[3]) / 2 for box in bounding_boxes]\n",
    "    y_unique = sorted(set(y_centers))\n",
    "\n",
    "    # Step 5-6: Adjust y coordinates\n",
    "    ye = [y_unique[0]]\n",
    "    for i in range(1, len(y_unique)):\n",
    "        if y_unique[i] - y_unique[i - 1] <= rt:\n",
    "            dy = 1\n",
    "        else:\n",
    "            dy = max(1, (y_unique[i] - y_unique[i - 1]) / rr)\n",
    "        ye.append(ye[-1] + dy)\n",
    "\n",
    "    # Step 7: Map old y centers to new ones\n",
    "    y_map = {old: new for old, new in zip(y_unique, ye)}\n",
    "    for box in bounding_boxes:\n",
    "        center_y = (box[1] + box[3]) / 2\n",
    "        new_center_y = y_map[center_y]\n",
    "        offset = new_center_y - center_y\n",
    "        box[1] += offset\n",
    "        box[3] += offset\n",
    "\n",
    "    # Step 8: Split into token-level boxes (simplified)\n",
    "    token_boxes = []\n",
    "    for box, text in zip(bounding_boxes, recognized_strings):\n",
    "        step = (box[2] - box[0]) / len(text)\n",
    "        for i, char in enumerate(text):\n",
    "            token_boxes.append([box[0] + i * step, box[1], box[0] + (i + 1) * step, box[3]])\n",
    "\n",
    "    # Step 9: Calculate average width of token boxes\n",
    "    widths = [box[2] - box[0] for box in token_boxes]\n",
    "    rw = np.mean(widths)\n",
    "\n",
    "    # Step 10: Normalize x coordinates\n",
    "    for box in token_boxes:\n",
    "        box[0] /= rw\n",
    "        box[2] /= rw\n",
    "\n",
    "    # Step 11-32: Initialize and fill the TextLattice matrix\n",
    "    x_centers = [(box[0] + box[2]) / 2 for box in token_boxes]\n",
    "    y_centers = [(box[1] + box[3]) / 2 for box in token_boxes]\n",
    "    xmin, xmax = min(x_centers), max(x_centers)\n",
    "    ymin, ymax = min(y_centers), max(y_centers)\n",
    "\n",
    "    # Initialize the TextLattice matrix\n",
    "    I = np.zeros((int(ymax - ymin + 1), int(xmax - xmin + 1)))\n",
    "\n",
    "    # Fill the TextLattice matrix\n",
    "    for box, char in zip(token_boxes, ''.join(recognized_strings)):\n",
    "        x_center = int((box[0] + box[2]) / 2 - xmin)\n",
    "        y_center = int((box[1] + box[3]) / 2 - ymin)\n",
    "        I[y_center, x_center] = ord(char)  # Simple embedding using ASCII values\n",
    "\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97. 109. 108. 101.   0. 116. 101. 120. 116.   0. 100.  97. 116.  97.]\n",
      " [102. 111.   0. 114. 116. 101. 116. 105. 103.   0. 116. 104.   0. 101.]\n",
      " [121. 116. 111. 110.   0.  99. 111. 100. 101.  97.  98. 111. 118. 101.]\n",
      " [ 84. 104. 105. 115.   0. 105.   0. 115.   0.   0.   0.  97.   0.   0.]\n",
      " [105. 109. 108. 101. 101. 120. 109. 112. 101. 105. 110. 112. 117. 116.]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "bounding_boxes = [\n",
    "    [10, 20, 110, 70],  # Coordinates for bounding box 1\n",
    "    [120, 20, 220, 70],  # Coordinates for bounding box 2\n",
    "    [230, 20, 330, 70],  # Coordinates for bounding box 3\n",
    "    [10, 80, 110, 130],  # Coordinates for bounding box 4\n",
    "    [120, 80, 220, 130],  # Coordinates for bounding box 5\n",
    "    [230, 80, 330, 130],  # Coordinates for bounding box 6\n",
    "    [10, 140, 110, 190],  # Coordinates for bounding box 7\n",
    "    [120, 140, 220, 190],  # Coordinates for bounding box 8\n",
    "    [230, 140, 330, 190],  # Coordinates for bounding box 9\n",
    "    [10, 200, 110, 250],  # Coordinates for bounding box 10\n",
    "    [120, 200, 220, 250],  # Coordinates for bounding box 11\n",
    "    [230, 200, 330, 250],  # Coordinates for bounding box 12\n",
    "    [10, 260, 110, 310],  # Coordinates for bounding box 13\n",
    "    [120, 260, 220, 310],  # Coordinates for bounding box 14\n",
    "    [230, 260, 330, 310]   # Coordinates for bounding box 15\n",
    "]\n",
    "\n",
    "recognized_strings = [\n",
    "    \"Sample\",  # Text recognized in bounding box 1\n",
    "    \"text\",    # Text recognized in bounding box 2\n",
    "    \"data\",    # Text recognized in bounding box 3\n",
    "    \"for\",     # Text recognized in bounding box 4\n",
    "    \"testing\", # Text recognized in bounding box 5\n",
    "    \"the\",     # Text recognized in bounding box 6\n",
    "    \"Python\",  # Text recognized in bounding box 7\n",
    "    \"code\",    # Text recognized in bounding box 8\n",
    "    \"above\",   # Text recognized in bounding box 9\n",
    "    \"This\",    # Text recognized in bounding box 10\n",
    "    \"is\",      # Text recognized in bounding box 11\n",
    "    \"a\",       # Text recognized in bounding box 12\n",
    "    \"simple\",  # Text recognized in bounding box 13\n",
    "    \"example\", # Text recognized in bounding box 14\n",
    "    \"input\"    # Text recognized in bounding box 15\n",
    "]\n",
    "rt = 10\n",
    "rr = 1.5\n",
    "\n",
    "processed_data = process_text_data(bounding_boxes, recognized_strings, rt, rr)\n",
    "print(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layout parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layoutparser as lp\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"/Users/avinash/Desktop/Personal projects/ocr_to_layout-text/dataset_images/Year Ending Cash Flow Statement/page_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module layoutparser has no attribute Detectron2LayoutModel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetectron2LayoutModel\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlp://PubLayNet/faster_rcnn_R_50_FPN_3x/config\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      2\u001b[0m                                  extra_config\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODEL.ROI_HEADS.SCORE_THRESH_TEST\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.8\u001b[39m],\n\u001b[1;32m      3\u001b[0m                                  label_map\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFigure\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/Desktop/Personal projects/ocr_to_layout-text/ocr_env/lib/python3.9/site-packages/layoutparser/file_utils.py:226\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    224\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mAttributeError\u001b[0m: module layoutparser has no attribute Detectron2LayoutModel"
     ]
    }
   ],
   "source": [
    "model = lp.Detectron2LayoutModel('lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config', \n",
    "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],x\n",
    "                                 label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\", 4:\"Figure\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
